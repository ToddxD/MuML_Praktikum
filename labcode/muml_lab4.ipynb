{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MuML Lab 4 - Deep Learning - CNN für die Solarzelleninspektion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ziel\n",
    "In diesem Versuch soll ein pre-trained CNN mit nur wenig Trainingsdaten auf eine neue Aufgabe angepasst werden, um Solarzellen erkennen zu können. \n",
    "Dies entspricht dem typischen Anwendungsfall, dass ein Klassifier zu programmieren ist, für dessen grundlegendes Training die Datenmenge nicht ausreicht.\n",
    "\n",
    "Die in den vorigen Laborversuchen selbst aufgenommenen Bilder sind von der Anzahl für diese Aufgabe nicht ausreichend. In Vorversuchen hat sich gezeigt, dass hiermit nur eine Genauigkeit von 40% erreicht werden konnte.\n",
    "\n",
    "Daher wird auf einen im Internet verfügbaren und in zwei Fehlerklassen (crack, dark area) gelabelten Datensatz zurückgegriffen:\n",
    "https://github.com/kirill-menke/resnet-defective-solar-cells?tab=readme-ov-file\n",
    "Da dieser bereits augmentierte Daten enthält, wurden diese um Augmentierungen bereinigt und es sind für diesen Versuch die 2000 Bilder des in der Datei ```data.csv``` gelabelten Ordners ```images``` verwendet werden.\n",
    "\n",
    "- Die Bilder 300 x 300 Pixel großen Bilder sollen auf eine Größe von 150 x 150 reduziert werden.\n",
    "- Die Batch-Größe soll 16 betragen.\n",
    "- Die Daten sollen im Verhältnis 60 - 20 - 20 auf Trainings-, Validierungs- und Testdaten aufgeteilt werden.\n",
    "- Als Optimizer soll AdamW genutzt werden. Zunächst ist die Lernrate auf 10e-4 voreinzustellen.\n",
    "- Es ist eine für das multi-label multi-class Problem geeignete Kostenfunktion zu wählen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benötigte Bibliotheken\n",
    "\n",
    "Aktiviere die Conda-Umgebung ```muml``` per ```conda activate muml``` nach Aufruf des Programms ```Anaconda Prompt``` und stelle durch Ausführen der folgenden Zelle sicher, sicher, dass alle benötigen Libraries installiert sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "print(\"Erfolgsmeldung: Alle Bibliotheken wurden erfolgreich importiert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grundeinstellungen\n",
    "\n",
    "Nachfolgend werden die in der Aufgabenstellung genannten Einstellungen als Konstanten definiert. Gegebenenfalls muss das Verzeichnis BASE_DIR für die Datei ```data.csv``` und den Ordner ```images``` angepasst werden. Auch wird geprüft, ob eine GPU angesprochen werden kann, die für diesen Laborversuch sehr empfohlen wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \".\"              # folder containing the data.csv file and the images folder\n",
    "CSV_FILE = \"data.csv\"       # name of the csv file containing the image labels\n",
    "\n",
    "TARGET_SIZE = (150, 150)    # target size for the images\n",
    "BATCH_SIZE = 16             # batch size for the training to be reduced to 8 if memory is not sufficient\n",
    "EPOCHS = 10                 # epochs for the training, should be reduced to 2 for test purposes to save time\n",
    "\n",
    "TRAIN_SPLIT = 0.6           # share of the training data\n",
    "VAL_SPLIT = 0.2             # share of validation data\n",
    "\n",
    "# check for GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"GPU empfohlen. Die nachfolgende Ausgabe sollte daher statt cpu als aktives Gerät cuda ausgeben:\")\n",
    "print(\"Aktives Gerät:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ausgangssituation\n",
    "\n",
    "Analysiere die CSV-Datei data.csv und die zur Verfügung gestellten Bilder stichprobenartig.\n",
    "\n",
    "**Aufbau von ```data.csv```:**\n",
    "```\n",
    "filename;crack;inactive\n",
    "images/cell2044.png;1;0\n",
    "images/cell0123.png;0;0\n",
    "```\n",
    "\n",
    "Der Zugriff auf die CSV-Datei und die Bilder ist nachfolgend beispielhaft demonstriert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load the CSV file with the shape file;label1;label2 with numpy\n",
    "data = np.genfromtxt(os.path.join(BASE_DIR, CSV_FILE), delimiter=';', dtype='str', skip_header=1)\n",
    "files = [os.path.join(BASE_DIR, row[0]) for row in data]\n",
    "labels = np.array([[row[1], row[2]] for row in data], dtype='int')\n",
    "\n",
    "# show the first 3 images\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(16):\n",
    "    img = cv2.imread(files[i])\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(labels[i])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Number of images: \", len(files))\n",
    "print(\"Image shape: \", img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.1 Baseline\n",
    "\n",
    "Es ist zunächst das Data Splitting zu analysieren und unter Nutzung von conditional indexing für Validation- und Test-Daten zu ergänzen.\n",
    "\n",
    "Anschließend ist als Baseline zu berechnen, welche Accuracy ein trivialer Klassifikator erreicht, der nur die häufigste Ausprägung ausgibt.\n",
    "Als Ausprägungen sind zu berücksichtigen:\n",
    "- [0, 0] - kein Fehler\n",
    "- [1, 0] - crack\n",
    "- [0, 1] - dark area bzw. inactive\n",
    "- [1, 1] - sowohl crack als auch dark area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for the multi-label classification with labels classified in csv file\n",
    "# CSV file: file;crack;inactive\n",
    "data = np.genfromtxt(os.path.join(BASE_DIR, CSV_FILE), delimiter=';', dtype='str', skip_header=1)\n",
    "files = [os.path.join(BASE_DIR, row[0]) for row in data]\n",
    "labels = np.array([[row[1], row[2]] for row in data], dtype='float32')\n",
    "\n",
    "# split the data into training, validation and test sets\n",
    "split_point1 = int(TRAIN_SPLIT * len(files))\n",
    "split_point2 = int((TRAIN_SPLIT + VAL_SPLIT) * len(files))\n",
    "indices = np.random.permutation(len(files))\n",
    "\n",
    "train_indices = indices[:split_point1]\n",
    "val_indices = indices[split_point1:split_point2]\n",
    "test_indices = indices[split_point2:]\n",
    "\n",
    "# train_files soll alle Dateinamen für das Training enthalten, train_labels die entsprechenden Labels\n",
    "train_files, train_labels = np.array(files)[train_indices], labels[train_indices]\n",
    "\n",
    "###########################\n",
    "# TODO: auf validation und test anwenden\n",
    "###########################\n",
    "\n",
    "###########################\n",
    "# TODO: Berechnung der Baseline für alle drei Datensätze\n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.2 Data augmentation\n",
    "\n",
    "Da es sich um ein multi-label multi-class Problem handelt, muss eine eigene Klasse MultiLabelDataset erstellt werden, die bereits implementiert ist.\n",
    "\n",
    "\n",
    "Anschließend ist der Code um Data augmentation zu ergänzen. Hierzu ist die Bibliothek v2 aus ```torchvision.transforms.v2``` zu nutzen. Siehe hierzu: https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_getting_started.html \n",
    "\n",
    "Es ist eine sinnvolle Auswahl von Operationen von Data Augmentation durchzuführen und zu begründen. Hierbei ist darauf zu achten, dass die Orientierung der Eingangsbilder nur geringfügig verändert wird, da die Strukturen der Solarzellen aufgrund der Kontaktiereinheit stets dieselbe Richtung aufweisen. Die korrekte Funktion ist anhand der Visualisierung eines Batches zu überprüfen.\n",
    "\n",
    "Die Fehlerbilder werden auf die TARGET_SIZE (150, 150) Pixel skaliert, um Rechenzeit zu sparen, dann zu einem Tensor und abschließend mit der für ImageNet-Datensätze notwendigen Normierung konvertiert:\n",
    "```transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])```\n",
    "\n",
    "Überprüfen Sie die korrekte Funktion des DataLoaders, indem Sie einen Mini-Batch generieren und die folgenden Ausgaben programmieren:\n",
    "\n",
    "1. Shape des Mini-Batches\n",
    "2. Wertebereich des Mini-Batches\n",
    "3. Ausgabe der Bilder des Batches und zugehörige Label als Titel. Dazu müssen die\n",
    "Bilder unter Nutzung der gefundenen min- und max-Werte auf 0 . . . 255 skaliert\n",
    "und der Tensor in ein Numpy-Array vom Typ np.uint8 umgewandelt werden.\n",
    "\n",
    "Hinweis: Nutzen Sie hierzu zweckmäßigerweise die Tensor-Methoden min(), max() sowie numpy() zur Umwandlung eines Tensors in ein numpy-Array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset for the multi-label classification\n",
    "class MultiLabelDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None, transform_name=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # DHL: unlike plt.imread, cv2.imread reads these image files as 3 channels instead of 1\n",
    "        # np_img = plt.imread(self.file_paths[idx])\n",
    "        np_img = cv2.imread(self.file_paths[idx])\n",
    "        img = Image.fromarray(np_img)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, self.labels[idx]\n",
    "\n",
    "\n",
    "# get the image, resize it to the target size and convert it to a tensor and normalize it to imagenet\n",
    "basic_transform = transforms.Compose([\n",
    "    v2.Resize(TARGET_SIZE),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "    \n",
    "])\n",
    "\n",
    "augmentation_transform = transforms.Compose([\n",
    "    v2.Resize(TARGET_SIZE),\n",
    "\n",
    "    ###########################\n",
    "    # TODO: data augmentation\n",
    "    ###########################\n",
    "    \n",
    "    v2.ToTensor(),\n",
    "    # normalize the image to imagenet parameters\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the train dataset with augmentation, the validation and test datasets with basic transform\n",
    "train_dataset = MultiLabelDataset(train_files, train_labels, transform=augmentation_transform)\n",
    "val_dataset = MultiLabelDataset(val_files, val_labels, transform=basic_transform)\n",
    "test_dataset = MultiLabelDataset(test_files, test_labels, transform=basic_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "def show_batch(dl):\n",
    "    for images, labels in dl:\n",
    "\n",
    "        ##############################################\n",
    "        # TODO: Display a batch of images and labels\n",
    "        ##############################################\n",
    "\n",
    "        plt.show()\n",
    "        break\n",
    "\n",
    "print(\"Labels: [ crack, dark area]\")\n",
    "print(\"Training set batch\")\n",
    "show_batch(train_loader)\n",
    "print(\"Validation set batch\")\n",
    "show_batch(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.3 Hilfsfunktionen zum Training und Testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_accuracy(outputs_one_hot, labels_one_hot):\n",
    "    \"\"\"compute accuracy for both one-hot encoded outputs and labels for \n",
    "    multilabel classification, a data point is considered as correct if\n",
    "    all labels are predicted correctly\"\"\"\n",
    "    \n",
    "    ######################################\n",
    "    # TODO: implement the function\n",
    "    acc = 0 # placeholder\n",
    "    ######################################\n",
    "    \n",
    "    return acc\n",
    "\n",
    "\n",
    "def train_epoch(model, criterion, optimizer, dataloader, device):\n",
    "    \"\"\" Training function for one epoch returns loss and accuracy\"\"\"\n",
    "    \n",
    "    ###########################################\n",
    "    # TODO: implement the function\n",
    "    loss = 0    # placeholder\n",
    "    acc = 0     # placeholder\n",
    "    \n",
    "    ###########################################\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def evaluate_model(model, criterion, dataloader, device):\n",
    "    \"\"\" Evaluation function for one epoch returns loss and accuracy\"\"\"\n",
    "    \n",
    "    ###########################################\n",
    "    # TODO: implement the function\n",
    "    loss = 0    # placeholder\n",
    "    acc = 0     # placeholder\n",
    "    ###########################################\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def plot_history(history, title=\"Trainingsverlauf\"):\n",
    "    \"\"\"show graphs of history-dictionary\n",
    "    one subplot for trainings and validation loss and one for training and validation accuracy\"\"\"\n",
    "    \n",
    "    ###########################################\n",
    "    # TODO: implement the function\n",
    "    ###########################################\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"print the number of trainable parameters and total parameters in a PyTorch model\"\"\"\n",
    "    \n",
    "    ###########################################\n",
    "    # TODO: implement the function\n",
    "    param_count = 0 # placeholder\n",
    "    ###########################################\n",
    "\n",
    "    return param_count\n",
    "\n",
    "\n",
    "def fit(model, criterion, optimizer, epochs):\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_accs': [], 'val_accs': []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        ##############################################\n",
    "        # TODO: implement the training and evaluation\n",
    "        history = {'train_loss': [], 'val_loss': [], 'train_accs': [], 'val_accs': []} # placeholder\n",
    "        ##############################################\n",
    "\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "print(\"Successfully done with imports and functions\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.4 Model 1 - VGG16 from scratch - no pretrained weights\n",
    "\n",
    "Beachte, dass die Shape des ersten Fully Connected Layer eine auf die Ausgabe des letzten Convolutional Layers angepasst werden muss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = models.vgg16(weights=None)   # initialize model\n",
    "conv_base = full_model.features\n",
    "\n",
    "# check output of conv_base to find appropriate input size for classifier\n",
    "test_output = conv_base(next(iter(train_loader))[0])\n",
    "print(f\"Conv-Layer Output of test batch: {test_output.shape}\")\n",
    "\n",
    "# Define the model with the pretrained VGG16 features and a custom classifier\n",
    "\n",
    "#####################################################################\n",
    "# TODO: Define the model either as sequential model or as class\n",
    "#####################################################################\n",
    "\n",
    "model.to(device)                        # use GPU if available\n",
    "model.eval()                            # set layers to evaluation mode\n",
    "\n",
    "\n",
    "# Define BCEWithLogitsLoss as the loss function for multi-label classification\n",
    "criterion = nn.BCEWithLogitsLoss()  # for binary proble use binary cross entropy loss\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "print(\"[i] Training of model_a: VGG16.featurs with own classifier\")\n",
    "print(\"[i] Number of trainable parameters:\", count_parameters(model))\n",
    "hist = fit(model, criterion, optimizer, EPOCHS)\n",
    "plot_history(hist, \"VGG16 from scratch - no pretrained weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.5 Modellvergleich\n",
    "\n",
    "- Modell 1: Modell ohne Transfer Learning wie oben\n",
    "- Modell 2: Modell mit auf Image-Net vortrainierter Convolutional Base und neu erstelltem Klassfikator\n",
    "- Modell 3: Modell mit auf Image-Net vortrainierter Convolutional Base, die eingefroren wird und mit neu erstelltem Klassfikator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.6 Hyperparameter-Tuning\n",
    "Die generierten Modelle aus der vorigen Teilaufgabe sind zu vergleichen und es ist das bestgeeignete begründet auszuwählen.\n",
    "\n",
    "Für dieses eine Modell soll im Rahmen des Hyperparameter-Tunings untersucht werden, welche Lernrate und welche Anzahl von Neuronen des ersten hidden Layers des Classifiers optimal sind. Hierzu soll die jeweils beste Validierungs-Accuracy (und die zugehörige Trainings-Accuracy) festgehalten werden. Diese besten Ergebnisse sind übersichtlich in einer Tabelle für die unterschiedlichen Lernraten und Anzahl der Neuronen darzustellen.\n",
    "\n",
    "Hinweis: Die Funktion ist zunächst bei nur 2 Epochen zu testen. Wenn die Funktion gegeben ist, dann auf 10 Epochen erweitern (besser 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATES = [1e-3, 1e-4]\n",
    "UNITS = [64, 128, 256, 512]\n",
    "EPOCHS_HYPER = 5\n",
    "\n",
    "final_accs = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "####################################################\n",
    "# TODO: implement the hyperparameter grid search\n",
    "####################################################\n",
    "\n",
    "stop = time.time()\n",
    "print(f\"Execution time for {len(final_accs)} runs is {stop - start:.0f} secs\")\n",
    "df = pd.DataFrame(final_accs, columns=['lr', 'units', 'best_train_acc', 'best val_acc'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.7 Evaluation\n",
    "\n",
    "Die optimale Netzwerkkonfiguration ist mit 30 Epochen zu trainieren und die beste Epoche in Bezug auf die Validierungs-Accuracy zu speichern. Dazu ist die Trainingsfunktion fit entsprechend zu erweitern.\n",
    "\n",
    "Es sind die folgenden Auswertungen durchzuführen:\n",
    "- Accuracy des Modells\n",
    "- Klassenweise Accuracy, Precision, Recall\n",
    "\n",
    "Auf dieser Grundlage ist das Ergebnis kritisch bezüglich folgendender Aspekte zu bewerten:\n",
    "- Vor- und Nachteile gegenüber der herkömmlichen Klassifikation aus dem vorigen Laborversuch\n",
    "- Ansätze für weitere Verbesserungen des Deep Learning-Ansatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# TODO: Train the best model as final_model and save \n",
    "# the model with the highest validation accuracy\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hilfsfunktionen zur Evalation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model instead of the last trained model\n",
    "model_final = torch.load(\"best.pth\")\n",
    "test_loss, test_acc = evaluate_model(model_final, criterion, test_loader, device)\n",
    "print(f\"Test Loss: {test_loss:.4f} - Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erwartungswerte zur Kontrolle: Die Test Accuracy sollte im Bereich von 90 bis 94 % liegen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klassenweise Accuracy\n",
    "\n",
    "Es ist eine Vorhersage auf einem Testdatenbatch auszuführen und jeweils ein zweispaltiges numpy Array der Vorhersagen mit den Werten 0 und 1 sowie ein numpy-Array der zugehörigen tatsächlichen Label auszugeben.\n",
    "Je Spalte ist dann eine Berechnung der geforderten Größen Acc, P,  R durchzuführen.\n",
    "\n",
    "**Hinweis:** Vor der Nutzung der Methode ```numpy()``` zur Umwandlung eines Tensors in ein numpy-Array ist der Tensor von der GPU in die CPU zu verschieben. Hierzu wird die Methode ```cpu()``` eingesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.eval()                              # Switch to evaluation mode\n",
    "with torch.no_grad():                           # Disable gradient computation for inference to save memory and computation time\n",
    "    all_labels = np.array([])                   # store labels of all batches\n",
    "    all_outputs = np.array([])                  # store outputs of all batches\n",
    "\n",
    "    for i, data in enumerate(test_loader):      # iterate over all test batches\n",
    "        inputs = data[0].to(device)             # get inputs and move to GPU if available\n",
    "        labels = data[1].to(device)             # get labels and move to GPU if available\n",
    "        outputs = model_final(inputs)           # forward pass\n",
    "        \n",
    "        if i == 0:\n",
    "            test_labels = labels.cpu().numpy()                                  # initial run: fill with first batch\n",
    "            test_outputs = outputs.cpu().numpy()                                  \n",
    "        else:\n",
    "            test_labels = np.vstack((test_labels, labels.cpu().numpy()))        # append the labels of the batch\n",
    "            test_outputs = np.vstack((test_outputs, outputs.cpu().numpy()))\n",
    "\n",
    "\n",
    "preds = (test_outputs > 0.5)                    # convert outputs to binary predictions\n",
    "print(\"Vorhersage: \", preds)                    # print predictions just for debugging\n",
    "\n",
    "\n",
    "for class_idx in range(2):\n",
    "    print(f\"Class {class_idx}\")\n",
    "    \n",
    "    ######################################\n",
    "    # TODO: implement the function\n",
    "    ######################################\n",
    "\n",
    "    print(f\"True Positives  : {true_positives}\")\n",
    "    print(f\"True Negatives  : {true_negatives}\")\n",
    "    print(f\"False Positives : {false_positives}\")\n",
    "    print(f\"False Negatives : {false_negatives}\")\n",
    "    print(f\"Accuracy        : {acc:.4f}\")\n",
    "    print(f\"Precision       : {precision:.4f}\")\n",
    "    print(f\"Recall          : {recall:.4f}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation des Ergebnisses\n",
    "\n",
    "-  Wie sind die Ergebnisse zu bewerten?\n",
    "- Finde Ansätze, wie man zu besseren Ergebnissen kommen kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative Analyse anhand eines Testbatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(model, loader, batch_nr=0):\n",
    "    \"\"\"function to show a batch of images with the true labels and the predicted labels\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(loader):\n",
    "            if i >= batch_nr:\n",
    "                images = data[0].to(device)\n",
    "                labels = data[1].to(device)\n",
    "                predictions = model(images.to(device))\n",
    "                break\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(len(images)):\n",
    "        img = images[i].permute(1, 2, 0).cpu().detach().numpy()\n",
    "        min_val = img.min()\n",
    "        max_val = img.max()\n",
    "        img = ((img - min_val) / (max_val - min_val) * 255).astype(np.uint8)\n",
    "        \n",
    "        prediction = (predictions[i].cpu().numpy() > 0).astype(np.uint8)\n",
    "        label = labels[i].cpu().numpy().astype(np.uint8)\n",
    "        plt.subplot(len(images) // 4 + 1, 4, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(str(label) + \" as \" + str(prediction))\n",
    "    plt.suptitle(\"Reihenfolge: [Crack, Dark Area]\", fontsize=16, y=0.92)\n",
    "    plt.show()\n",
    "\n",
    "# Display some test images with their predictions\n",
    "print(\"Test set batch\")\n",
    "show_batch(model_final, test_loader, 0)\n",
    "print(\"Validation set batch\")\n",
    "show_batch(model_final, val_loader, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "cacc07851db34b79d56d860315375ace82a5e72debbec4d58679cead2b51acee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
